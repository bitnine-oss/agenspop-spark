[[1;34mINFO[m] Scanning for projects...
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------< [0;36mnet.bitnine:agenspop-spark[0;1m >---------------------[m
[[1;34mINFO[m] [1mBuilding agenspop-spark 0.7.3[m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mspring-boot-maven-plugin:2.1.7.RELEASE:run[m [1m(default-cli)[0;1m > [0;1mtest-compile[m @ [36magenspop-spark[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:3.1.0:resources[m [1m(default-resources)[m @ [36magenspop-spark[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] Copying 4 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mscala-maven-plugin:4.1.1:add-source[m [1m(scala-compile-first)[m @ [36magenspop-spark[0;1m ---[m
[[1;34mINFO[m] Add Source directory: /hdd_ext/hdd1t/Workspaces/agens/agenspop-spark/src/main/scala
[[1;34mINFO[m] Add Test Source directory: /hdd_ext/hdd1t/Workspaces/agens/agenspop-spark/src/test/scala
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mscala-maven-plugin:4.1.1:compile[m [1m(scala-compile-first)[m @ [36magenspop-spark[0;1m ---[m
[[1;34mINFO[m] Using incremental compilation using Mixed compile order
[[1;34mINFO[m] Compiling 4 Scala sources and 20 Java sources to /hdd_ext/hdd1t/Workspaces/agens/agenspop-spark/target/classes ...
[[1;34mINFO[m] [Info] /hdd_ext/hdd1t/Workspaces/agens/agenspop-spark/src/main/java/net/bitnine/agenspopspark/job/SparkJob.java:-1: Some input files use unchecked or unsafe operations.
[[1;34mINFO[m] [Info] /hdd_ext/hdd1t/Workspaces/agens/agenspop-spark/src/main/java/net/bitnine/agenspopspark/job/SparkJob.java:-1: Recompile with -Xlint:unchecked for details.
[[1;34mINFO[m] Scanning for projects...
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m---------------------< [0;36mnet.bitnine:agenspop-spark[0;1m >---------------------[m
[[1;34mINFO[m] [1mBuilding agenspop-spark 0.7.3[m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m>>> [0;32mspring-boot-maven-plugin:2.1.7.RELEASE:run[m [1m(default-cli)[0;1m > [0;1mtest-compile[m @ [36magenspop-spark[0;1m >>>[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:3.1.0:resources[m [1m(default-resources)[m @ [36magenspop-spark[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] Copying 4 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mscala-maven-plugin:4.1.1:add-source[m [1m(scala-compile-first)[m @ [36magenspop-spark[0;1m ---[m
[[1;34mINFO[m] Add Source directory: /hdd_ext/hdd1t/Workspaces/agens/agenspop-spark/src/main/scala
[[1;34mINFO[m] Add Test Source directory: /hdd_ext/hdd1t/Workspaces/agens/agenspop-spark/src/test/scala
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mscala-maven-plugin:4.1.1:compile[m [1m(scala-compile-first)[m @ [36magenspop-spark[0;1m ---[m
[[1;34mINFO[m] Using incremental compilation using Mixed compile order
[[1;34mINFO[m] Compiling 4 Scala sources and 20 Java sources to /hdd_ext/hdd1t/Workspaces/agens/agenspop-spark/target/classes ...
[[1;34mINFO[m] [Info] /hdd_ext/hdd1t/Workspaces/agens/agenspop-spark/src/main/java/net/bitnine/agenspopspark/job/SparkJob.java:-1: Some input files use unchecked or unsafe operations.
[[1;34mINFO[m] [Info] /hdd_ext/hdd1t/Workspaces/agens/agenspop-spark/src/main/java/net/bitnine/agenspopspark/job/SparkJob.java:-1: Recompile with -Xlint:unchecked for details.
Run target jar: target/agenspop-spark-0.7.3.jar(es-config)
log4j:WARN No appenders could be found for logger (org.springframework.web.context.support.StandardServletEnvironment).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
20/06/26 12:19:40 WARN Utils: Your hostname, minubt resolves to a loopback address: 127.0.1.1; using 192.168.0.30 instead (on interface enp37s0)
20/06/26 12:19:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
20/06/26 12:19:40 INFO SparkContext: Running Spark version 2.4.6
20/06/26 12:19:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/06/26 12:19:41 INFO SparkContext: Submitted application: es-bitnine
20/06/26 12:19:41 INFO SecurityManager: Changing view acls to: bgmin
20/06/26 12:19:41 INFO SecurityManager: Changing modify acls to: bgmin
20/06/26 12:19:41 INFO SecurityManager: Changing view acls groups to: 
20/06/26 12:19:41 INFO SecurityManager: Changing modify acls groups to: 
20/06/26 12:19:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(bgmin); groups with view permissions: Set(); users  with modify permissions: Set(bgmin); groups with modify permissions: Set()
20/06/26 12:19:42 INFO Utils: Successfully started service 'sparkDriver' on port 36625.
20/06/26 12:19:42 INFO SparkEnv: Registering MapOutputTracker
20/06/26 12:19:42 INFO SparkEnv: Registering BlockManagerMaster
20/06/26 12:19:42 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/06/26 12:19:42 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/06/26 12:19:42 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2bdcb73c-c2a5-407b-b490-f0afb42ba7ab
20/06/26 12:19:42 INFO MemoryStore: MemoryStore started with capacity 4.0 GB
20/06/26 12:19:42 INFO SparkEnv: Registering OutputCommitCoordinator
20/06/26 12:19:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/06/26 12:19:42 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.0.30:4040
20/06/26 12:19:42 INFO SparkContext: Added JAR jars/elasticsearch-hadoop-7.7.1.jar at spark://192.168.0.30:36625/jars/elasticsearch-hadoop-7.7.1.jar with timestamp 1593141582749
20/06/26 12:19:42 INFO SparkContext: Added JAR jars/elasticsearch-spark-20_2.11-7.7.1.jar at spark://192.168.0.30:36625/jars/elasticsearch-spark-20_2.11-7.7.1.jar with timestamp 1593141582750
20/06/26 12:19:42 INFO SparkContext: Added JAR jars/graphframes-0.8.0-spark2.4-s_2.11.jar at spark://192.168.0.30:36625/jars/graphframes-0.8.0-spark2.4-s_2.11.jar with timestamp 1593141582751
20/06/26 12:19:42 INFO Executor: Starting executor ID driver on host localhost
20/06/26 12:19:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44341.
20/06/26 12:19:42 INFO NettyBlockTransferService: Server created on 192.168.0.30:44341
20/06/26 12:19:42 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/06/26 12:19:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.0.30, 44341, None)
20/06/26 12:19:43 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.0.30:44341 with 4.0 GB RAM, BlockManagerId(driver, 192.168.0.30, 44341, None)
20/06/26 12:19:43 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.0.30, 44341, None)
20/06/26 12:19:43 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.0.30, 44341, None)

** ready!! 
==================================

** BEAN: sparkConf
==>
es.mapping.date.rich=false
spark.app.name=es-bitnine
spark.es.mapping.date.rich=false
spark.home=/home/bgmin/Servers/spark
spark.jars=jars/elasticsearch-hadoop-7.7.1.jar,jars/elasticsearch-spark-20_2.11-7.7.1.jar,jars/graphframes-0.8.0-spark2.4-s_2.11.jar
spark.master=local

==================================

** spark.job-monitor.url ==> http://<local>:4040/

